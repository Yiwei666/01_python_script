# 上手案例

# 1. 甲烷分子

## 1. 数据准备

### 1. 数据划分脚本

- 参考文档及案例数据下载：https://bohrium.dp.tech/notebooks/3313403083

- 从 ABACUS/MD 格式的数据中读取 201 帧原子结构，随机选取 40 帧作为验证集，其余作为训练集并分别生成子系统。然后将这两部分数据导出为 DeepMD-kit 所需的 .npy 格式，存放到指定的训练和验证文件夹中。


```py
import dpdata 
import numpy as np

# 读入 ABACUS/MD 格式的数据
data = dpdata.LabeledSystem('DeePMD-kit_Tutorial/00.data/abacus_md', fmt = 'abacus/md') 
print('# 数据包含%d帧' % len(data))

# 随机选择40个索引作为验证集数据
index_validation = np.random.choice(201,size=40,replace=False)

# 其他索引作为训练集数据
index_training = list(set(range(201))-set(index_validation))
data_training = data.sub_system(index_training)
data_validation = data.sub_system(index_validation)

# 将所有训练数据放入文件夹"training_data"中
data_training.to_deepmd_npy('DeePMD-kit_Tutorial/00.data/training_data')

# 将所有验证数据放入文件夹"validation_data"中
data_validation.to_deepmd_npy('DeePMD-kit_Tutorial/00.data/validation_data')

print('# 训练数据包含%d帧' % len(data_training)) 
print('# 验证数据包含%d帧' % len(data_validation))
```


### 2. 划分训练/验证集

```py
>>> import dpdata
>>> import numpy as np
>>>
>>> # 读入 ABACUS/MD 格式的数据
>>> data = dpdata.LabeledSystem('DeePMD-kit_Tutorial/00.data/abacus_md', fmt = 'abacus/md')
>>> print('# 数据包含%d帧' % len(data))
# 数据包含201帧
```

```py
>>> # 随机选择40个索引作为验证集数据
>>> index_validation = np.random.choice(201,size=40,replace=False)
>>>
>>> # 其他索引作为训练集数据
>>> index_training = list(set(range(201))-set(index_validation))
>>> data_training = data.sub_system(index_training)
>>> data_validation = data.sub_system(index_validation)
>>>
>>> # 将所有训练数据放入文件夹"training_data"中
>>> data_training.to_deepmd_npy('DeePMD-kit_Tutorial/00.data/training_data')
>>>
>>> # 将所有验证数据放入文件夹"validation_data"中
>>> data_validation.to_deepmd_npy('DeePMD-kit_Tutorial/00.data/validation_data')
>>>
>>> print('# 训练数据包含%d帧' % len(data_training))
# 训练数据包含161帧
>>> print('# 验证数据包含%d帧' % len(data_validation))
# 验证数据包含40帧
```


- 生成训练数据和验证数据

```
├── DeePMD-kit_Tutorial
    ├── 00.data
        ├── abacus_md
            ├── C_ONCV_PBE-1.2.upf
            ├── C_gga_6au_100Ry_2s2p1d.orb
            ├── H_ONCV_PBE-1.2.upf
            ├── H_gga_6au_100Ry_2s1p.orb
            ├── INPUT
            ├── KPT
            ├── OUT.ABACUS
            └── STRU
        ├── training_data
            ├── set.000
            ├── type.raw
            └── type_map.raw
        └── validation_data
            ├── set.000
            ├── type.raw
            └── type_map.raw
    ├── 01.train
        └── input.json
    └── 02.lmp
        ├── conf.lmp
        └── in.lammps
```


1. 在 00.data 下新出现的 training_data 和 validation_data 目录，分别就是为 DeepMD-kit 准备好的训练集和验证集数据，每个目录里：

   - set.000/：存放若干帧的 .npy 文件（如 `coord.npy、box.npy、energy.npy、force.npy` 等），对应原子坐标、晶胞、能量和力等物理量；

   - type.raw：一维数组，记录每帧中各原子的类型索引；

   - type_map.raw：将类型索引映射到实际元素类别（或原子种类）的列表。

2. 这些文件／文件夹就是 DeePMD-kit 所要求的标准 .npy 格式输入，用于后续的模型训练（training_data）和性能验证（validation_data）。





## 2. 输入脚本

### 1. 示例 input.json

- 相对位置位于 `DeePMD-kit_Tutorial\01.train\input.json`路径下

`input.json` 内容如下：

```json
{
    "_comment": " model parameters",
    "model": {
  "type_map": ["H", "C"],
  "descriptor" :{
      "type":   "se_e2_a",
      "sel":    "auto",
      "rcut_smth":  0.50,
      "rcut":   6.00,
      "neuron":   [25, 50, 100],
      "resnet_dt":  false,
      "axis_neuron":  16,
      "seed":   1,
      "_comment":   " that's all"
  },
  "fitting_net" : {
      "neuron":   [240, 240, 240],
      "resnet_dt":  true,
      "seed":   1,
      "_comment":   " that's all"
  },
  "_comment": " that's all"
    },

    "learning_rate" :{
  "type":   "exp",
  "decay_steps":  50,
  "start_lr": 0.001,  
  "stop_lr":  3.51e-8,
  "_comment": "that's all"
    },

    "loss" :{
  "type":   "ener",
  "start_pref_e": 0.02,
  "limit_pref_e": 1,
  "start_pref_f": 1000,
  "limit_pref_f": 1,
  "start_pref_v": 0,
  "limit_pref_v": 0,
  "_comment": " that's all"
    },

    "training" : {
  "training_data": {
      "systems":     ["../00.data/training_data"],
      "batch_size":  "auto",
      "_comment":    "that's all"
  },
  "validation_data":{
      "systems":     ["../00.data/validation_data"],
      "batch_size":  "auto",
      "numb_btch":   1,
      "_comment":    "that's all"
  },
  "numb_steps": 10000,
  "seed":   10,
  "disp_file":  "lcurve.out",
  "disp_freq":  200,
  "save_freq":  1000,
  "_comment": "that's all"
    },    

    "_comment":   "that's all"
}
```




## 3. 训练模型

### 1. 超算提交脚本

1. 本地运行命令

```sh
cd DeePMD-kit_Tutorial/01.train/ && dp train input.json
```


2. 超算提交脚本


```sh
#!/bin/bash
#SBATCH -p amd_256
#SBATCH -N 1
#SBATCH -c 64

# OpenMP 线程数
export OMP_NUM_THREADS=8

# TensorFlow 并行度（DeepMD-kit v2.2.1 只认这俩）
# export TF_INTRA_OP_PARALLELISM_THREADS=8
# export TF_INTER_OP_PARALLELISM_THREADS=8

# （可选）同时保留新版本别名
export DP_INTRA_OP_PARALLELISM_THREADS=8
export DP_INTER_OP_PARALLELISM_THREADS=8

source /public21/home/sc90511/deepmd-kit/bin/activate
dp train input.json  > train.out 2>&1
```




### 2. 并行核数测试

1. 官方参考文档：https://docs.deepmodeling.com/projects/deepmd/en/stable/troubleshooting/howtoset_num_nodes.html

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20250425-094202.png" alt="Image Description" width="700">
</p>


```sh
export OMP_NUM_THREADS=16
export DP_INTRA_OP_PARALLELISM_THREADS=16
export DP_INTER_OP_PARALLELISM_THREADS=8
```

2. 案例测试表明
   - 上面三个环境变量都不设置，训练总耗时为 172 s，单批次训练耗时 3.3 s
   - 按照 64*0*0 设置，训练总耗时为 193 s，单批次训练耗时 3.8 s
   - 按照 16*16*4 设置，训练总耗时为 121 s，单批次训练耗时 2.3 s
   - 按照 8*8*8 设置，训练总耗时为 119 s，单批次训练耗时 2.26 s
   - 按照 4*4*16 设置，训练总耗时为 122 s，单批次训练耗时 2.3 s


3. 官方推荐参数设置

   - 针对单节点 64 核的情况，核心原则是不让并行流数（`DP_INTER_OP_THREADS`）与每流线程数（`DP_INTRA_OP_THREADS` 或 `OMP_NUM_THREADS`）之积超过 64。

   - 参数设置原则

```sh
OMP_NUM_THREADS 核数 = DP_INTRA_OP_PARALLELISM_THREADS 核数
DP_INTRA_OP_PARALLELISM_THREADS 乘以 DP_INTER_OP_PARALLELISM_THREADS = 总核心数
```


| 变量                            | 控制范围                               | 典型取值建议                                               |
|-------------------------------|----------------------------------------|------------------------------------------------------------|
| `mpirun -np $P`               | 进程数量（多节点/多卡/多进程）         | 根据可用节点或 GPU 数目决定                                |
| `DP_INTER_OP_PARALLELISM_THREADS` | 同时启动多少算子流                     | 一般设为进程内部核心数的一半（经验值）                     |
| `DP_INTRA_OP_PARALLELISM_THREADS` | 每个算子内部线程池大小                 | 视算子复杂度，一般和 `OMP_NUM_THREADS` 保持一致           |
| `OMP_NUM_THREADS`            | OpenMP 线程数                           | 保证 `P × DP_INTER × DP_INTRA × OMP ≤ CPU` 核心总数        |






### 3. 输出文件


- lcurve.out

1. 训练步数
2. 验证损失
3. 训练损失
4. 能量的均方根（RMS）验证误差
5. 能量的 RMS 训练误差
6. 力的 RMS 验证误差
7. 力的 RMS 训练误差
8. 学习率




```py
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

with open("./DeePMD-kit_Tutorial/01.train/lcurve.out") as f:
    headers = f.readline().split()[1:]
lcurve = pd.DataFrame(np.loadtxt("./DeePMD-kit_Tutorial/01.train/lcurve.out"), columns=headers)
legends = ["rmse_e_val", "rmse_e_trn", "rmse_f_val" , "rmse_f_trn" ]

for legend in legends:
    plt.loglog(lcurve["step"], lcurve[legend], label = legend )
plt.legend()
plt.xlabel("Training steps")
plt.ylabel("Loss")
plt.show()
```


请修改上述python代码，打印当前目录下的所有文件名，然后提示用户输入文件名，再读取数据进行绘图。注意修改的只是上述代码中数据文件的路径








## 4. 冻结模型

```
dp freeze -o graph.pb
```



## 5. 压缩模型

```
dp compress -i graph.pb -o compress.pb
```



## 6. 测试模型

```
dp test -m graph.pb -s ../00.data/validation_data
```



```py
import dpdata

training_systems = dpdata.LabeledSystem("./DeePMD-kit_Tutorial/00.data/training_data", fmt = "deepmd/npy")  # 得到训练数据点
predict = training_systems.predict("./DeePMD-kit_Tutorial/01.train/graph.pb")  # 得到预测数据点


import matplotlib.pyplot as plt
import numpy as np

plt.scatter(training_systems["energies"], predict["energies"])

x_range = np.linspace(plt.xlim()[0], plt.xlim()[1])

plt.plot(x_range, x_range, "r--", linewidth = 0.25)
plt.xlabel("Energy of DFT")  # 设置 x 轴标题
plt.ylabel("Energy predicted by deep potential")  # 设置 y 轴标题
plt.show()
```



## 7. 使用lammps进行MD计算








