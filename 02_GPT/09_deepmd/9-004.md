# 上手案例

# 1. 甲烷分子

## 1. 数据准备

### 1. 数据划分脚本

- 参考文档及案例数据下载：https://bohrium.dp.tech/notebooks/3313403083

- 从 ABACUS/MD 格式的数据中读取 201 帧原子结构，随机选取 40 帧作为验证集，其余作为训练集并分别生成子系统。然后将这两部分数据导出为 DeepMD-kit 所需的 .npy 格式，存放到指定的训练和验证文件夹中。


```py
import dpdata 
import numpy as np

# 读入 ABACUS/MD 格式的数据
data = dpdata.LabeledSystem('DeePMD-kit_Tutorial/00.data/abacus_md', fmt = 'abacus/md') 
print('# 数据包含%d帧' % len(data))

# 随机选择40个索引作为验证集数据
index_validation = np.random.choice(201,size=40,replace=False)

# 其他索引作为训练集数据
index_training = list(set(range(201))-set(index_validation))
data_training = data.sub_system(index_training)
data_validation = data.sub_system(index_validation)

# 将所有训练数据放入文件夹"training_data"中
data_training.to_deepmd_npy('DeePMD-kit_Tutorial/00.data/training_data')

# 将所有验证数据放入文件夹"validation_data"中
data_validation.to_deepmd_npy('DeePMD-kit_Tutorial/00.data/validation_data')

print('# 训练数据包含%d帧' % len(data_training)) 
print('# 验证数据包含%d帧' % len(data_validation))
```


### 2. 划分训练/验证集

```py
>>> import dpdata
>>> import numpy as np
>>>
>>> # 读入 ABACUS/MD 格式的数据
>>> data = dpdata.LabeledSystem('DeePMD-kit_Tutorial/00.data/abacus_md', fmt = 'abacus/md')
>>> print('# 数据包含%d帧' % len(data))
# 数据包含201帧
```

```py
>>> # 随机选择40个索引作为验证集数据
>>> index_validation = np.random.choice(201,size=40,replace=False)
>>>
>>> # 其他索引作为训练集数据
>>> index_training = list(set(range(201))-set(index_validation))
>>> data_training = data.sub_system(index_training)
>>> data_validation = data.sub_system(index_validation)
>>>
>>> # 将所有训练数据放入文件夹"training_data"中
>>> data_training.to_deepmd_npy('DeePMD-kit_Tutorial/00.data/training_data')
>>>
>>> # 将所有验证数据放入文件夹"validation_data"中
>>> data_validation.to_deepmd_npy('DeePMD-kit_Tutorial/00.data/validation_data')
>>>
>>> print('# 训练数据包含%d帧' % len(data_training))
# 训练数据包含161帧
>>> print('# 验证数据包含%d帧' % len(data_validation))
# 验证数据包含40帧
```


- 生成训练数据和验证数据

```
├── DeePMD-kit_Tutorial
    ├── 00.data
        ├── abacus_md
            ├── C_ONCV_PBE-1.2.upf
            ├── C_gga_6au_100Ry_2s2p1d.orb
            ├── H_ONCV_PBE-1.2.upf
            ├── H_gga_6au_100Ry_2s1p.orb
            ├── INPUT
            ├── KPT
            ├── OUT.ABACUS
            └── STRU
        ├── training_data
            ├── set.000
            ├── type.raw
            └── type_map.raw
        └── validation_data
            ├── set.000
            ├── type.raw
            └── type_map.raw
    ├── 01.train
        └── input.json
    └── 02.lmp
        ├── conf.lmp
        └── in.lammps
```


1. 在 00.data 下新出现的 training_data 和 validation_data 目录，分别就是为 DeepMD-kit 准备好的训练集和验证集数据，每个目录里：

   - set.000/：存放若干帧的 .npy 文件（如 `coord.npy、box.npy、energy.npy、force.npy` 等），对应原子坐标、晶胞、能量和力等物理量；

   - type.raw：一维数组，记录每帧中各原子的类型索引；

   - type_map.raw：将类型索引映射到实际元素类别（或原子种类）的列表。

2. 这些文件／文件夹就是 DeePMD-kit 所要求的标准 .npy 格式输入，用于后续的模型训练（training_data）和性能验证（validation_data）。





## 2. 输入脚本

### 1. 示例 input.json

- 相对位置位于 `DeePMD-kit_Tutorial\01.train\input.json`路径下

`input.json` 内容如下：

```json
{
    "_comment": " model parameters",
    "model": {
  "type_map": ["H", "C"],
  "descriptor" :{
      "type":   "se_e2_a",
      "sel":    "auto",
      "rcut_smth":  0.50,
      "rcut":   6.00,
      "neuron":   [25, 50, 100],
      "resnet_dt":  false,
      "axis_neuron":  16,
      "seed":   1,
      "_comment":   " that's all"
  },
  "fitting_net" : {
      "neuron":   [240, 240, 240],
      "resnet_dt":  true,
      "seed":   1,
      "_comment":   " that's all"
  },
  "_comment": " that's all"
    },

    "learning_rate" :{
  "type":   "exp",
  "decay_steps":  50,
  "start_lr": 0.001,  
  "stop_lr":  3.51e-8,
  "_comment": "that's all"
    },

    "loss" :{
  "type":   "ener",
  "start_pref_e": 0.02,
  "limit_pref_e": 1,
  "start_pref_f": 1000,
  "limit_pref_f": 1,
  "start_pref_v": 0,
  "limit_pref_v": 0,
  "_comment": " that's all"
    },

    "training" : {
  "training_data": {
      "systems":     ["../00.data/training_data"],
      "batch_size":  "auto",
      "_comment":    "that's all"
  },
  "validation_data":{
      "systems":     ["../00.data/validation_data"],
      "batch_size":  "auto",
      "numb_btch":   1,
      "_comment":    "that's all"
  },
  "numb_steps": 10000,
  "seed":   10,
  "disp_file":  "lcurve.out",
  "disp_freq":  200,
  "save_freq":  1000,
  "_comment": "that's all"
    },    

    "_comment":   "that's all"
}
```




## 3. 训练模型

### 1. 超算提交脚本

1. 本地运行命令

```sh
cd DeePMD-kit_Tutorial/01.train/ && dp train input.json
```


2. 超算提交脚本


```sh
#!/bin/bash
#SBATCH -p amd_256
#SBATCH -N 1
#SBATCH -c 64

# OpenMP 线程数
export OMP_NUM_THREADS=8

# TensorFlow 并行度（DeepMD-kit v2.2.1 只认这俩）
# export TF_INTRA_OP_PARALLELISM_THREADS=8
# export TF_INTER_OP_PARALLELISM_THREADS=8

# （可选）同时保留新版本别名
export DP_INTRA_OP_PARALLELISM_THREADS=8
export DP_INTER_OP_PARALLELISM_THREADS=8

source /public21/home/sc90511/deepmd-kit/bin/activate
dp train input.json  > train.out 2>&1
```




### 2. 并行核数测试

1. 官方参考文档：https://docs.deepmodeling.com/projects/deepmd/en/stable/troubleshooting/howtoset_num_nodes.html

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20250425-094202.png" alt="Image Description" width="700">
</p>




2. 案例测试
   - 下面三个环境变量都不设置，训练总耗时为 172 s，单批次训练耗时 3.3 s
   - 按照 64 * 0 * 0 设置，训练总耗时为 193 s，单批次训练耗时 3.8 s
   - 按照 16 * 16 * 4 设置，训练总耗时为 121 s，单批次训练耗时 2.3 s
   - 按照 8 * 8 * 8 设置，训练总耗时为 119 s，单批次训练耗时 2.26 s
   - 按照 4 * 4 * 16 设置，训练总耗时为 122 s，单批次训练耗时 2.3 s

```sh
export OMP_NUM_THREADS=16
export DP_INTRA_OP_PARALLELISM_THREADS=16
export DP_INTER_OP_PARALLELISM_THREADS=8
```


4. 官方推荐参数设置

   - 针对单节点 64 核的情况，核心原则是不让并行流数（`DP_INTER_OP_THREADS`）与每流线程数（`DP_INTRA_OP_THREADS` 或 `OMP_NUM_THREADS`）之积超过 64。

   - 参数设置原则

```sh
OMP_NUM_THREADS 核数 = DP_INTRA_OP_PARALLELISM_THREADS 核数
DP_INTRA_OP_PARALLELISM_THREADS 乘以 DP_INTER_OP_PARALLELISM_THREADS = 总核心数
```


| 变量                            | 控制范围                               | 典型取值建议                                               |
|-------------------------------|----------------------------------------|------------------------------------------------------------|
| `mpirun -np $P`               | 进程数量（多节点/多卡/多进程）         | 根据可用节点或 GPU 数目决定                                |
| `DP_INTER_OP_PARALLELISM_THREADS` | 同时启动多少算子流                     | 一般设为进程内部核心数的一半（经验值）                     |
| `DP_INTRA_OP_PARALLELISM_THREADS` | 每个算子内部线程池大小                 | 视算子复杂度，一般和 `OMP_NUM_THREADS` 保持一致           |
| `OMP_NUM_THREADS`            | OpenMP 线程数                           | 保证 `P × DP_INTER × DP_INTRA × OMP ≤ CPU` 核心总数        |






### 3. 输出文件`lcurve.out`

- `lcurve.out`

```txt
#  step      rmse_val    rmse_trn    rmse_e_val  rmse_e_trn    rmse_f_val  rmse_f_trn         lr
      0      1.70e+01    1.83e+01      1.38e-01    1.35e-01      5.38e-01    5.78e-01    1.0e-03
    200      4.46e+00    4.67e+00      1.92e+00    1.92e+00      1.41e-01    1.49e-01    8.1e-04
    400      3.11e+00    3.31e+00      5.33e-01    5.33e-01      1.18e-01    1.25e-01    6.6e-04
    600      2.62e+00    2.68e+00      1.08e-01    1.08e-01      1.12e-01    1.15e-01    5.4e-04
    800      1.95e+00    1.60e+00      3.84e-02    3.76e-02      9.29e-02    7.60e-02    4.4e-04
   1000      1.25e+00    1.50e+00      1.26e-02    1.32e-02      6.58e-02    7.92e-02    3.6e-04
   1200      1.17e+00    1.10e+00      6.75e-03    6.89e-03      6.81e-02    6.45e-02    2.9e-04
   1400      6.37e-01    8.75e-01      9.16e-03    9.96e-03      4.12e-02    5.67e-02    2.4e-04
   1600      4.97e-01    8.30e-01      1.89e-03    1.10e-03      3.56e-02    5.95e-02    1.9e-04
   1800      6.98e-01    6.28e-01      1.82e-03    1.80e-03      5.54e-02    4.99e-02    1.6e-04
   ........
   8800      4.50e-02    3.79e-02      6.30e-04    5.30e-04      4.25e-02    3.58e-02    1.2e-07
   9000      3.83e-02    4.44e-02      5.23e-04    7.41e-04      3.65e-02    4.23e-02    9.8e-08
   9200      3.55e-02    4.13e-02      6.50e-04    7.88e-04      3.41e-02    3.97e-02    8.0e-08
   9400      3.96e-02    4.35e-02      5.01e-04    5.47e-04      3.84e-02    4.21e-02    6.5e-08
   9600      4.90e-02    4.30e-02      8.34e-04    7.11e-04      4.77e-02    4.19e-02    5.3e-08
   9800      4.20e-02    3.79e-02      5.52e-04    5.87e-04      4.11e-02    3.70e-02    4.3e-08
  10000      2.56e-02    4.48e-02      6.40e-04    7.62e-04      2.51e-02    4.40e-02    3.5e-08
```


- 各列参数含义：

1. 训练步数 step

训练到的迭代步数（batch 次数）。

2. 验证损失 rmse_val

验证集上的“总损失”RMS（根均方误差）。这里的总损失是能量误差和力误差按预设权重加权后的组合指标，用来综合评估模型在未见数据上的表现。

3. 训练损失 rmse_trn

训练集上的“总损失”RMS，含义同上，但评估对象是在训练过程中使用的样本。

4. 能量的均方根（RMS）验证误差 rmse_e_val

验证集上能量预测的 RMS 误差（单位通常是 eV/atom），并且 DeepMD-kit 会对体系中每帧的总能量误差按原子数归一化。

5. 能量的 RMS 训练误差 rmse_e_trn

训练集上能量预测的 RMS 误差，含义同上。

6. 力的 RMS 验证误差 rmse_f_val

验证集上力预测的 RMS 误差（单位通常是 eV/Å）。

7. 力的 RMS 训练误差 rmse_f_trn

训练集上力预测的 RMS 误差。

8. 学习率 lr

当前步的学习率，用于监控学习率衰减策略（例如指数衰减）是否按预期在降低。


<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20250425-100125.png" alt="Image Description" width="500">
</p>



- 数据分析：

1. 收敛性与稳定性

   - 随着 step 增加，若 rmse_trn 和 rmse_val 都能持续下降并趋于平稳，说明模型在训练和验证上都在收敛。

   - 若 rmse_trn 下降而 rmse_val 停滞或反弹，则可能存在过拟合，需要考虑增加正则化、减小模型复杂度或提前停止（early stopping）。

2. 能量 vs. 力的误差平衡

   - 一般而言，力的 RMS 误差对 MD 模拟的精度影响更大。常见目标：能量误差 < 1 meV/atom，力误差 < 0.1 eV/Å。

   - 如果 rmse_e_val 较低而 rmse_f_val 较高，说明模型对能量拟合很好，但对力场细节把握不足，此时可调整 loss 权重（在 input.json 的 loss 部分增大 force 权重）。

3. 学习率（lr）策略

   - 观察 lr 随 step 的衰减：应与输入脚本中设置的 decay_steps、decay_rate 相对应。学习率下降到很小但误差仍未继续下降，说明已经到达收敛极限，可考虑停训或调整初始 lr/衰减率。

4. 模型选择

   - 通常以 最低的验证集能量误差 或 力误差 作为选取最佳模型的准则。可在对应 step 时保存 checkpoint，用于后续 freeze。

   - 如果对能量和力都有要求，也可以同时对比 rmse_e_val 和 rmse_f_val，选择二者综合较优的点。

5. 可视化

   - 将上述各指标对 step 作对数–对数或半对数图，有助于直观判断收敛速率、拐点和振荡情况。




















- 可视化脚本

```py
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

with open("./DeePMD-kit_Tutorial/01.train/lcurve.out") as f:
    headers = f.readline().split()[1:]
lcurve = pd.DataFrame(np.loadtxt("./DeePMD-kit_Tutorial/01.train/lcurve.out"), columns=headers)
legends = ["rmse_e_val", "rmse_e_trn", "rmse_f_val" , "rmse_f_trn" ]

for legend in legends:
    plt.loglog(lcurve["step"], lcurve[legend], label = legend )
plt.legend()
plt.xlabel("Training steps")
plt.ylabel("Loss")
plt.show()
```











## 4. 冻结模型

```
dp freeze -o graph.pb
```



## 5. 压缩模型

```
dp compress -i graph.pb -o compress.pb
```



## 6. 测试模型

```
dp test -m graph.pb -s ../00.data/validation_data
```



```py
import dpdata

training_systems = dpdata.LabeledSystem("./DeePMD-kit_Tutorial/00.data/training_data", fmt = "deepmd/npy")  # 得到训练数据点
predict = training_systems.predict("./DeePMD-kit_Tutorial/01.train/graph.pb")  # 得到预测数据点


import matplotlib.pyplot as plt
import numpy as np

plt.scatter(training_systems["energies"], predict["energies"])

x_range = np.linspace(plt.xlim()[0], plt.xlim()[1])

plt.plot(x_range, x_range, "r--", linewidth = 0.25)
plt.xlabel("Energy of DFT")  # 设置 x 轴标题
plt.ylabel("Energy predicted by deep potential")  # 设置 y 轴标题
plt.show()
```



## 7. 使用lammps进行MD计算








