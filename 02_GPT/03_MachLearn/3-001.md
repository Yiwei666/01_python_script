# 无监督学习

# 1. 主成分分析

### 1. 协方差矩阵

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240616-155357.png" alt="Image Description" width="700">
</p>


### 2. 鸢尾花PCA

接下来，我将使用 `scikit-learn` 的鸢尾花数据集（Iris）作为示例，来展示如何使用PCA进行数据分析和可视化。这个数据集包含150个样本，每个样本有4个特征，分别是花萼长度、花萼宽度、花瓣长度和花瓣宽度。

1. 手动实现PCA代码

```py
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.preprocessing import StandardScaler

# 加载数据
iris = datasets.load_iris()
X = iris.data

# 步骤 1: 数据标准化
scaler = StandardScaler()
X_std = scaler.fit_transform(X)
print("标准化后的数据：")
print(X_std[:5])  # 打印前5行数据

# 步骤 2: 计算协方差矩阵
cov_matrix = np.cov(X_std.T)
print("\n协方差矩阵：")
print(cov_matrix)

# 步骤 3: 计算协方差矩阵的特征值和特征向量
eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)
print("\n特征值：")
print(eigenvalues)
print("\n特征向量：")
print(eigenvectors)

# 步骤 4: 对特征向量排序，并选择主要特征向量
# 排序特征值并提取前两个最大的
indices = np.argsort(eigenvalues)[::-1]
eigenvalues_sorted = eigenvalues[indices]
eigenvectors_sorted = eigenvectors[:, indices]

print("\n排序后的特征值：")
print(eigenvalues_sorted)
print("\n排序后的特征向量：")
print(eigenvectors_sorted)

# 选择前两个特征向量
projection_matrix = eigenvectors_sorted[:, :2]
print("\n投影矩阵 (前两个特征向量)：")
print(projection_matrix)

# 步骤 5: 数据转换
X_pca = X_std.dot(projection_matrix)
print("\n降维后的数据：")
print(X_pca[:5])  # 打印前5行数据

# 可视化结果
plt.figure(figsize=(8, 6))
for i, target_name in zip([0, 1, 2], iris.target_names):
    plt.scatter(X_pca[iris.target == i, 0], X_pca[iris.target == i, 1], label=target_name)
plt.legend()
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA of IRIS Dataset (Manual Steps)')
plt.show()
```

2. 使用sklearn的PCA类

```py
# 导入必要的库
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.datasets import load_iris

# 加载鸢尾花数据集
data = load_iris()
X = data.data
y = data.target
target_names = data.target_names

# 创建PCA对象，设定降维后的主成分数量为2
pca = PCA(n_components=2)

# 对数据进行降维
X_r = pca.fit_transform(X)

# 可视化
plt.figure()
colors = ['navy', 'turquoise', 'darkorange']
lw = 2

for color, i, target_name in zip(colors, [0, 1, 2], target_names):
    plt.scatter(X_r[y == i, 0], X_r[y == i, 1], color=color, alpha=.8, lw=lw,
                label=target_name)
plt.legend(loc='best', shadow=False, scatterpoints=1)
plt.title('PCA of IRIS dataset')
plt.show()
```



### 3. 数据分析

1. 投影数据可视化

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240616-161210.png" alt="Image Description" width="450">
</p>

2. 数据分析

解释：

- **标准化后的数据**：对原始数据进行标准化，使每个特征的平均值为0，标准差为1。打印标准化后的数据的前5行。
- **协方差矩阵**：计算标准化数据的协方差矩阵，显示各个特征之间的协方差。
- **特征值和特征向量**：计算协方差矩阵的特征值和特征向量，并打印它们。
- **排序后的特征值和特征向量**：按照特征值的大小对特征值和特征向量进行排序，并打印排序结果。
- **投影矩阵**：选择前两个特征向量，构成投影矩阵，并打印出来。
- **降维后的数据**：使用投影矩阵将标准化后的数据转换到新的二维空间，并打印转换后的数据的前5行。


3. 过程数据

```
标准化后的数据：
[[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]
 [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]
 [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]
 [-1.50652052  0.09821729 -1.2833891  -1.3154443 ]
 [-1.02184904  1.24920112 -1.34022653 -1.3154443 ]]

协方差矩阵：
[[ 1.00671141 -0.11835884  0.87760447  0.82343066]
 [-0.11835884  1.00671141 -0.43131554 -0.36858315]
 [ 0.87760447 -0.43131554  1.00671141  0.96932762]
 [ 0.82343066 -0.36858315  0.96932762  1.00671141]]

特征值：
[2.93808505 0.9201649  0.14774182 0.02085386]

特征向量：
[[ 0.52106591 -0.37741762 -0.71956635  0.26128628]
 [-0.26934744 -0.92329566  0.24438178 -0.12350962]
 [ 0.5804131  -0.02449161  0.14212637 -0.80144925]
 [ 0.56485654 -0.06694199  0.63427274  0.52359713]]

排序后的特征值：
[2.93808505 0.9201649  0.14774182 0.02085386]

排序后的特征向量：
[[ 0.52106591 -0.37741762 -0.71956635  0.26128628]
 [-0.26934744 -0.92329566  0.24438178 -0.12350962]
 [ 0.5804131  -0.02449161  0.14212637 -0.80144925]
 [ 0.56485654 -0.06694199  0.63427274  0.52359713]]

投影矩阵 (前两个特征向量)：
[[ 0.52106591 -0.37741762]
 [-0.26934744 -0.92329566]
 [ 0.5804131  -0.02449161]
 [ 0.56485654 -0.06694199]]

降维后的数据：
[[-2.26470281 -0.4800266 ]
 [-2.08096115  0.67413356]
 [-2.36422905  0.34190802]
 [-2.29938422  0.59739451]
 [-2.38984217 -0.64683538]]
```



# 参考资料
