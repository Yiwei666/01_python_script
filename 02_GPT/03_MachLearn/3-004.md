# æ·±åº¦å­¦ä¹ 

# 1. åŸºæœ¬æ¦‚å¿µ

### 1. æ¡ä»¶åˆ†å¸ƒçš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240704-110530.png" alt="Image Description" width="700">
</p>

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240704-110743.png" alt="Image Description" width="700">
</p>

### 2. äº¤å‰ç†µå’ŒKLæ•£åº¦

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240701-142123.png" alt="Image Description" width="700">
</p>

### 3. æŸå¤±å‡½æ•°

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240629-163959.png" alt="Image Description" width="700">
</p>

### 4. æ¿€æ´»å‡½æ•°ï¼ˆè¾“å‡ºå•å…ƒï¼‰

- å…¸å‹è¾“å‡ºå•å…ƒ

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240629-163525.png" alt="Image Description" width="700">
</p>

- ä¸åŒè¾“å‡ºå•å…ƒçš„æŸå¤±å‡½æ•°

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240704-142801.png" alt="Image Description" width="700">
</p>

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240704-143021.png" alt="Image Description" width="700">
</p>

- å›¾åƒ

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240701-113622.png" alt="Image Description" width="700">
</p>

- ç»˜å›¾ä»£ç 

```py
import numpy as np
import matplotlib.pyplot as plt

# å®šä¹‰Sigmoidå‡½æ•°
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# å®šä¹‰Tanhå‡½æ•°
def tanh(x):
    return np.tanh(x)

# å®šä¹‰ReLUå‡½æ•°
def relu(x):
    return np.maximum(0, x)

# å®šä¹‰Softmaxå‡½æ•°
def softmax(x):
    e_x = np.exp(x - np.max(x))  # å‡å»æœ€å¤§å€¼ä»¥æé«˜æ•°å€¼ç¨³å®šæ€§
    return e_x / e_x.sum(axis=0)

# ç”Ÿæˆxå€¼
x = np.linspace(-10, 10, 100)

# åˆ›å»ºä¸€ä¸ªå›¾å½¢å’Œå››ä¸ªå­å›¾ï¼ˆ2x2å¸ƒå±€ï¼‰
fig, axs = plt.subplots(2, 2, figsize=(12, 10))

# ç»˜åˆ¶Sigmoidå‡½æ•°
axs[0, 0].plot(x, sigmoid(x), label='Sigmoid', color='blue')
axs[0, 0].set_title('Sigmoid Activation Function')
axs[0, 0].grid(True)
axs[0, 0].set_xlabel('X')
axs[0, 0].set_ylabel('Y')

# ç»˜åˆ¶Tanhå‡½æ•°
axs[0, 1].plot(x, tanh(x), label='Tanh', color='red')
axs[0, 1].set_title('Tanh Activation Function')
axs[0, 1].grid(True)
axs[0, 1].set_xlabel('X')
axs[0, 1].set_ylabel('Y')

# ç»˜åˆ¶ReLUå‡½æ•°
axs[1, 0].plot(x, relu(x), label='ReLU', color='green')
axs[1, 0].set_title('ReLU Activation Function')
axs[1, 0].grid(True)
axs[1, 0].set_xlabel('X')
axs[1, 0].set_ylabel('Y')

# ç»˜åˆ¶Softmaxå‡½æ•°
# æ³¨æ„ï¼šSoftmaxé€šå¸¸ç”¨äºå¤šç±»åˆ†ç±»ï¼Œè¿™é‡Œä¸ºäº†ç¤ºèŒƒï¼Œæˆ‘ä»¬åªæ˜¯å±•ç¤ºå•å˜é‡çš„Softmax
axs[1, 1].plot(x, softmax(x), label='Softmax', color='purple')
axs[1, 1].set_title('Softmax Activation Function')
axs[1, 1].grid(True)
axs[1, 1].set_xlabel('X')
axs[1, 1].set_ylabel('Y')

# ä¸ºæ¯ä¸ªå­å›¾æ·»åŠ å›¾ä¾‹
for ax in np.ravel(axs):  # ä½¿ç”¨ np.ravel å¤„ç†ç´¢å¼•
    ax.legend()

# è‡ªåŠ¨è°ƒæ•´å­å›¾é—´è·
plt.tight_layout()

# æ˜¾ç¤ºå›¾å½¢
plt.show()
```

### 5. æ¢¯åº¦ä¸‹é™å’Œå­¦ä¹ ç‡

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240701-143101.png" alt="Image Description" width="700">
</p>

### 6. éšæœºæ¢¯åº¦ä¸‹é™å’Œå°æ‰¹é‡æ¢¯åº¦ä¸‹é™

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240701-143727.png" alt="Image Description" width="700">
</p>


### 7. è¯¯å·®åå‘ä¼ æ’­æ³•

1. åŸºæœ¬æ¦‚å¿µ

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240629-172253.png" alt="Image Description" width="700">
</p>

2. ç†è®ºæ¨å¯¼

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240629-172636.png" alt="Image Description" width="700">
</p>

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240629-172851.png" alt="Image Description" width="700">
</p>

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240629-173024.png" alt="Image Description" width="700">
</p>

3. å®ä¾‹åŒ–

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240629-174356.png" alt="Image Description" width="700">
</p>

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240629-174749.png" alt="Image Description" width="700">
</p>


### 8. ä¸‡èƒ½é€¼è¿‘å®šç†

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240704-161246.png" alt="Image Description" width="700">
</p>


# 2. æ€§èƒ½åº¦é‡

### 1. æ¦‚è¿°

1. æ€§èƒ½åº¦é‡çš„å®šä¹‰ï¼š

- æ€§èƒ½åº¦é‡æ˜¯æŒ‡ç”¨äºè¡¡é‡æ¨¡å‹åœ¨é¢„æµ‹ã€åˆ†ç±»æˆ–å…¶ä»–ä»»åŠ¡ä¸­çš„è¡¨ç°çš„å„ç§æ•°å€¼æŒ‡æ ‡ã€‚è¿™äº›æŒ‡æ ‡æ—¨åœ¨æè¿°æ¨¡å‹çš„æ­£ç¡®æ€§å’Œé”™è¯¯ç‡ï¼Œä»¥åŠåœ¨é”™è¯¯å‘ç”Ÿæ—¶çš„å…·ä½“æƒ…å†µã€‚


### 2. æ¦‚ç‡åŸºç¡€

- æ€§èƒ½åº¦é‡é€šå¸¸åŸºäºæ¦‚ç‡ç†è®ºï¼Œæè¿°æ¨¡å‹åœ¨ä¸åŒæƒ…å†µä¸‹çš„é¢„æµ‹æ¦‚ç‡ã€‚æ–‡æ¡£ä»‹ç»äº†ç®€å•æ¦‚ç‡ã€æ¡ä»¶æ¦‚ç‡å’Œè”åˆæ¦‚ç‡ç­‰åŸºæœ¬æ¦‚å¿µï¼Œå¹¶é€šè¿‡æŠ•æ·é£é•–çš„æ¯”å–»æ¥è§£é‡Šè¿™äº›æ¦‚ç‡çš„è®¡ç®—å’Œæ„ä¹‰ã€‚

- æ¡ä»¶æ¦‚ç‡å’Œè”åˆæ¦‚ç‡ç¤ºæ„å›¾

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240710-113322.png" alt="Image Description" width="700">
</p>

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240709-214817.png" alt="Image Description" width="700">
</p>




# 3. å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼ˆFCNï¼‰

### 1. ç¥ç»å…ƒå’Œå‘å‰ä¼ æ’­

1. ç¥ç»å…ƒç¤ºæ„å›¾

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240704-151742.png" alt="Image Description" width="450">
</p>

2. æ·±åº¦ç¥ç»ç½‘ç»œç¤ºæ„å›¾

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240704-151832.png" alt="Image Description" width="600">
</p>

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240709-173427.png" alt="Image Description" width="800">
</p>


3. å‘å‰ä¼ æ’­çš„çŸ©é˜µå’Œå‘é‡ä¸€èˆ¬è¡¨ç¤º

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240704-152027.png" alt="Image Description" width="700">
</p>

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240704-152106.png" alt="Image Description" width="700">
</p>



### 2. åå‘ä¼ æ’­æ¼”ç¤º

ä¸ºäº†æ¼”ç¤ºæ¢¯åº¦ä¸‹é™åœ¨ç¥ç»ç½‘ç»œä¸­çš„åº”ç”¨ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œç¤ºä¾‹ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªè¾“å…¥å±‚ã€ä¸€ä¸ªéšè—å±‚ï¼ˆåªæœ‰ä¸€ä¸ªç¥ç»å…ƒï¼‰å’Œä¸€ä¸ªè¾“å‡ºå±‚ï¼ˆåŒæ ·åªæœ‰ä¸€ä¸ªç¥ç»å…ƒï¼‰ï¼Œæ¥é¢„æµ‹ä¸€äº›çº¿æ€§æ•°æ®ã€‚

å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªç®€å•çš„çº¿æ€§å…³ç³» `y=2x+1`ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ¥å­¦ä¹ è¿™ä¸ªå…³ç³»ã€‚

```py
import numpy as np
import matplotlib.pyplot as plt

# ä½¿ç”¨NumPyç”Ÿæˆçº¿æ€§æ•°æ®ï¼Œå¹¶æ·»åŠ ä¸€äº›é«˜æ–¯å™ªå£°
np.random.seed(42)  # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡å¤
x = np.linspace(-1, 1, 100)  # ç”Ÿæˆ100ä¸ªç­‰é—´éš”çš„xå€¼ï¼ŒèŒƒå›´ä»-1åˆ°1
y = 2 * x + 1 + np.random.randn(*x.shape) * 0.4  # çœŸå®çš„yå€¼åŸºäºçº¿æ€§å…³ç³»2x + 1ï¼Œå¹¶æ·»åŠ å™ªå£°

# åˆå§‹åŒ–ç¥ç»ç½‘ç»œå‚æ•°ï¼šæƒé‡å’Œåç½®
w1 = np.random.randn()  # éšè—å±‚æƒé‡
b1 = np.random.randn()  # éšè—å±‚åç½®
w2 = np.random.randn()  # è¾“å‡ºå±‚æƒé‡
b2 = np.random.randn()  # è¾“å‡ºå±‚åç½®

# è®¾ç½®å­¦ä¹ ç‡
learning_rate = 0.01

# å®šä¹‰æ¿€æ´»å‡½æ•°åŠå…¶å¯¼æ•°ï¼šè¿™é‡Œä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°
def activation(z):
    return z  # çº¿æ€§æ¿€æ´»

def activation_prime(z):
    return 1  # çº¿æ€§æ¿€æ´»å‡½æ•°çš„å¯¼æ•°

# è®­ç»ƒè¿‡ç¨‹
num_epochs = 100  # è®¾ç½®è¿­ä»£æ¬¡æ•°
for epoch in range(num_epochs):
    for i in range(len(x)):
        # å‰å‘ä¼ æ’­
        z1 = x[i] * w1 + b1  # è®¡ç®—éšè—å±‚çš„è¾“å…¥
        a1 = activation(z1)  # è®¡ç®—éšè—å±‚çš„è¾“å‡º
        z2 = a1 * w2 + b2  # è®¡ç®—è¾“å‡ºå±‚çš„è¾“å…¥
        a2 = activation(z2)  # è®¡ç®—è¾“å‡ºå±‚çš„è¾“å‡º

        # è®¡ç®—æŸå¤±ï¼ˆå‡æ–¹è¯¯å·®ï¼‰
        loss = (a2 - y[i]) ** 2

        # åå‘ä¼ æ’­ï¼šè®¡ç®—æŸå¤±å‡½æ•°å…³äºå„ä¸ªå‚æ•°çš„å¯¼æ•°
        dloss_da2 = 2 * (a2 - y[i])
        da2_dz2 = activation_prime(z2)
        dz2_dw2 = a1
        dz2_db2 = 1
        dz2_da1 = w2
        da1_dz1 = activation_prime(z1)
        dz1_dw1 = x[i]
        dz1_db1 = 1

        # è®¡ç®—æ¢¯åº¦
        dloss_dw2 = dloss_da2 * da2_dz2 * dz2_dw2
        dloss_db2 = dloss_da2 * da2_dz2 * dz2_db2
        dloss_dw1 = dloss_da2 * da2_dz2 * dz2_da1 * da1_dz1 * dz1_dw1
        dloss_db1 = dloss_da2 * da2_dz2 * dz2_da1 * da1_dz1 * dz1_db1

        # æ›´æ–°æƒé‡å’Œåç½®
        w2 -= learning_rate * dloss_dw2
        b2 -= learning_rate * dloss_db2
        w1 -= learning_rate * dloss_dw1
        b1 -= learning_rate * dloss_db1

# ç»˜åˆ¶è®­ç»ƒç»“æœ
predicted = activation(activation(x * w1 + b1) * w2 + b2)
plt.scatter(x, y, color='red', label='Data Points')  # åŸå§‹æ•°æ®ç‚¹
plt.plot(x, predicted, label='Fitted Line')  # æ‹Ÿåˆæ›²çº¿
plt.legend()
plt.show()
```

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240701-151840.png" alt="Image Description" width="700">
</p>

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240701-151924.png" alt="Image Description" width="700">
</p>


### 3. è®­ç»ƒè¿‡ç¨‹åŠ¨æ€è§†å›¾

ğŸ’ å›¾åƒ

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240701-153603.png" alt="Image Description" width="800">
</p>

1. æŸå¤±å†å²ï¼ˆLoss Historyï¼‰
   - è§‚å¯Ÿåˆ°çš„ç°è±¡ï¼šæŸå¤±å€¼åœ¨å¼€å§‹æ—¶è¿…é€Ÿä¸‹é™ï¼Œè¿™è¡¨æ˜æ¨¡å‹åœ¨æœ€åˆè¿­ä»£ä¸­å­¦ä¹ äº†å¤§é‡çš„ä¿¡æ¯ã€‚éšåï¼ŒæŸå¤±å€¼è¶‹äºç¨³å®šï¼Œå‘ˆç°å‡ºä¸€ç§å‘¨æœŸæ€§çš„å°æ³¢åŠ¨ã€‚
   - å¯èƒ½çš„è§£é‡Šï¼šåˆå§‹å¿«é€Ÿä¸‹é™å¯èƒ½ç”±äºæƒé‡å’Œåç½®ä»éšæœºå€¼å‘æ›´ä¼˜è§£è°ƒæ•´ã€‚ç¨³å®šåçš„å°æ³¢åŠ¨å¯èƒ½æ˜¯å› ä¸ºå­¦ä¹ ç‡ç›¸å¯¹è¾ƒå°æˆ–æ¨¡å‹å·²æ¥è¿‘æœ€ä¼˜è§£ä½†è¿˜åœ¨å¾®è°ƒã€‚

2. æƒé‡å†å²ï¼ˆWeight w1 and w2 Historyï¼‰
   - æƒé‡ w1 å’Œ w2ï¼šä¸¤ä¸ªæƒé‡éƒ½æ˜¾ç¤ºå‡ºå¿«é€Ÿçš„åˆå§‹å˜åŒ–ï¼Œç„¶åé€æ¸å¹³ç¨³ã€‚w1 å’Œ w2 çš„å˜åŒ–è¶‹åŠ¿è¡¨æ˜ï¼Œæ¨¡å‹å‚æ•°åœ¨ç»è¿‡åˆæœŸè°ƒæ•´ååŸºæœ¬ç¨³å®šã€‚
   - æƒé‡è°ƒæ•´ï¼šå¿«é€Ÿçš„åˆå§‹å˜åŒ–å¯èƒ½æ˜¯æ¨¡å‹åœ¨è¯•å›¾æ‰¾åˆ°é€‚åº”æ•°æ®çš„æœ€ä½³æ–¹å¼ã€‚ä¹‹åå˜åŒ–å¹³ç¼“å¯èƒ½æ„å‘³ç€æ¨¡å‹å·²ç»æ‰¾åˆ°äº†åˆé€‚çš„å‚æ•°è®¾ç½®ã€‚

3. åç½®å†å²ï¼ˆBias b1 and b2 Historyï¼‰
   - åç½® b1 å’Œ b2ï¼šåç½®çš„å˜åŒ–è¶‹åŠ¿ä¸æƒé‡ç±»ä¼¼ï¼Œåˆå§‹æœ‰è¾ƒå¤§çš„è°ƒæ•´ï¼Œéšåå˜åŒ–å¹…åº¦å‡å°ã€‚b1 åœ¨è°ƒæ•´åè¶‹äºç¨³å®šï¼Œè€Œ b2 åœ¨åˆå§‹è·³è·ƒåä¹Ÿè¶‹äºå¹³ç¨³ã€‚
   - å½±å“è§£é‡Šï¼šåç½®çš„è°ƒæ•´å¸®åŠ©æ¨¡å‹åœ¨ç‰¹å¾ç©ºé—´ä¸­æ­£ç¡®å®šä½å†³ç­–è¾¹ç•Œã€‚ç¨³å®šåçš„åç½®è¡¨æ˜æ¨¡å‹åœ¨æ•°æ®ä¸Šçš„åå·®å·²ç»è¾ƒå°ã€‚

4. æ¨¡å‹æ‹Ÿåˆï¼ˆModel Fitï¼‰
   - æ‹Ÿåˆæ•ˆæœï¼šä»æ¨¡å‹æ‹Ÿåˆå›¾çœ‹ï¼Œæ‹Ÿåˆçº¿ï¼ˆè“è‰²ï¼‰ä¸æ•°æ®ç‚¹ï¼ˆçº¢è‰²ï¼‰éå¸¸æ¥è¿‘ï¼Œè¯´æ˜æ¨¡å‹æœ‰æ•ˆåœ°å­¦ä¹ äº†æ•°æ®ä¸­çš„çº¿æ€§å…³ç³»ã€‚
   - æ•ˆæœè¯„ä¼°ï¼šæ¨¡å‹èƒ½å¤Ÿå¾ˆå¥½åœ°é¢„æµ‹æˆ–è¿‘ä¼¼çœŸå®æ•°æ®åˆ†å¸ƒï¼Œè¿™è¡¨æ˜æ‰€é€‰çš„ç½‘ç»œæ¶æ„å’Œè®­ç»ƒç­–ç•¥æ˜¯æœ‰æ•ˆçš„ã€‚



ğŸ’ ç»˜å›¾ä»£ç 

```py
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

# ä½¿ç”¨NumPyç”Ÿæˆçº¿æ€§æ•°æ®ï¼Œå¹¶æ·»åŠ ä¸€äº›é«˜æ–¯å™ªå£°
np.random.seed(42)  # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡å¤
x = np.linspace(-1, 1, 100)  # ç”Ÿæˆ100ä¸ªç­‰é—´éš”çš„xå€¼ï¼ŒèŒƒå›´ä»-1åˆ°1
y = 2 * x + 1 + np.random.randn(*x.shape) * 0.4  # çœŸå®çš„yå€¼åŸºäºçº¿æ€§å…³ç³»2x + 1ï¼Œå¹¶æ·»åŠ å™ªå£°

# åˆå§‹åŒ–ç¥ç»ç½‘ç»œå‚æ•°ï¼šæƒé‡å’Œåç½®
w1 = np.random.randn()  # éšè—å±‚æƒé‡
b1 = np.random.randn()  # éšè—å±‚åç½®
w2 = np.random.randn()  # è¾“å‡ºå±‚æƒé‡
b2 = np.random.randn()  # è¾“å‡ºå±‚åç½®

# è®¾ç½®å­¦ä¹ ç‡
learning_rate = 0.01

# å®šä¹‰æ¿€æ´»å‡½æ•°åŠå…¶å¯¼æ•°ï¼šè¿™é‡Œä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°
def activation(z):
    return z  # çº¿æ€§æ¿€æ´»

def activation_prime(z):
    return 1  # çº¿æ€§æ¿€æ´»å‡½æ•°çš„å¯¼æ•°

# åˆå§‹åŒ–è®°å½•æŸå¤±å’Œå‚æ•°å˜åŒ–çš„åˆ—è¡¨
loss_history = []
w1_history, b1_history, w2_history, b2_history = [], [], [], []

# è®­ç»ƒè¿‡ç¨‹
num_epochs = 100  # è®¾ç½®è¿­ä»£æ¬¡æ•°
for epoch in tqdm(range(num_epochs), desc="Training Progress"):
    for i in range(len(x)):
        # å‰å‘ä¼ æ’­
        z1 = x[i] * w1 + b1  # è®¡ç®—éšè—å±‚çš„è¾“å…¥
        a1 = activation(z1)  # è®¡ç®—éšè—å±‚çš„è¾“å‡º
        z2 = a1 * w2 + b2  # è®¡ç®—è¾“å‡ºå±‚çš„è¾“å…¥
        a2 = activation(z2)  # è®¡ç®—è¾“å‡ºå±‚çš„è¾“å‡º

        # è®¡ç®—æŸå¤±ï¼ˆå‡æ–¹è¯¯å·®ï¼‰
        loss = (a2 - y[i])**2
        loss_history.append(loss)  # è®°å½•æ¯æ¬¡çš„æŸå¤±å€¼

        # åå‘ä¼ æ’­ï¼šè®¡ç®—æŸå¤±å‡½æ•°å…³äºå„ä¸ªå‚æ•°çš„å¯¼æ•°
        dloss_da2 = 2 * (a2 - y[i])
        da2_dz2 = activation_prime(z2)
        dz2_dw2 = a1
        dz2_db2 = 1
        dz2_da1 = w2
        da1_dz1 = activation_prime(z1)
        dz1_dw1 = x[i]
        dz1_db1 = 1

        # è®¡ç®—æ¢¯åº¦
        dloss_dw2 = dloss_da2 * da2_dz2 * dz2_dw2
        dloss_db2 = dloss_da2 * da2_dz2 * dz2_db2
        dloss_dw1 = dloss_da2 * da2_dz2 * dz2_da1 * da1_dz1 * dz1_dw1
        dloss_db1 = dloss_da2 * da2_dz2 * dz2_da1 * da1_dz1 * dz1_db1

        # æ›´æ–°æƒé‡å’Œåç½®
        w2 -= learning_rate * dloss_dw2
        b2 -= learning_rate * dloss_db2
        w1 -= learning_rate * dloss_dw1
        b1 -= learning_rate * dloss_db1

        # ä¿å­˜æƒé‡å’Œåç½®å†å²
        w1_history.append(w1)
        b1_history.append(b1)
        w2_history.append(w2)
        b2_history.append(b2)

# ç»˜åˆ¶æŸå¤±å†å²
plt.figure(figsize=(14, 7))
plt.subplot(2, 3, 1)
plt.plot(loss_history, label='Loss over time')
plt.title('Loss History')
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.legend()

# ç»˜åˆ¶æƒé‡å’Œåç½®å˜åŒ–
plt.subplot(2, 3, 2)
plt.plot(w1_history, label='w1')
plt.title('Weight w1 History')
plt.legend()

plt.subplot(2, 3, 3)
plt.plot(b1_history, label='b1')
plt.title('Bias b1 History')
plt.legend()

plt.subplot(2, 3, 4)
plt.plot(w2_history, label='w2')
plt.title('Weight w2 History')
plt.legend()

plt.subplot(2, 3, 5)
plt.plot(b2_history, label='b2')
plt.title('Bias b2 History')
plt.legend()

# ç»˜åˆ¶æ¨¡å‹æ‹Ÿåˆç»“æœ
plt.subplot(2, 3, 6)
plt.scatter(x, y, color='red', label='Data Points')  # åŸå§‹æ•°æ®ç‚¹
predicted = activation(activation(x * w1 + b1) * w2 + b2)
plt.plot(x, predicted, label='Fitted Line', color='blue')  # æ‹Ÿåˆæ›²çº¿
plt.title('Model Fit')
plt.legend()

plt.tight_layout()
plt.show()
```

### 4. å…¨è¿æ¥ç¥ç»ç½‘ç»œç¼ºç‚¹

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240701-160849.png" alt="Image Description" width="700">
</p>




# 4. Iris å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰

### 1. æ¦‚è¿°

1. å®šä¹‰ï¼šå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMultilayer Perceptron, MLPï¼‰æ˜¯ä¸€ç§å‰é¦ˆç¥ç»ç½‘ç»œï¼Œé€šå¸¸ç”±è¾“å…¥å±‚ã€ä¸€ä¸ªæˆ–å¤šä¸ªéšè—å±‚å’Œè¾“å‡ºå±‚ç»„æˆã€‚æ¯ä¸€å±‚çš„ç¥ç»å…ƒä¸ä¸Šä¸€å±‚çš„æ‰€æœ‰ç¥ç»å…ƒç›¸è¿æ¥ã€‚

2. ç‰¹ç‚¹ï¼š

- å…¨è¿æ¥å±‚ï¼šMLP ä¸­æ¯ä¸ªç¥ç»å…ƒä¸å‰ä¸€å±‚çš„æ‰€æœ‰ç¥ç»å…ƒç›¸è¿æ¥ï¼Œè¿™ç§°ä¸ºå…¨è¿æ¥å±‚ï¼ˆFully Connected Layerï¼‰ã€‚
- éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼šå¸¸ç”¨çš„æ¿€æ´»å‡½æ•°åŒ…æ‹¬ ReLUï¼ˆRectified Linear Unitï¼‰ã€Sigmoid å’Œ Tanhã€‚
- é€‚ç”¨äºç»“æ„åŒ–æ•°æ®ï¼šMLP é€šå¸¸ç”¨äºå¤„ç†ç»“æ„åŒ–æ•°æ®ï¼Œå¦‚è¡¨æ ¼æ•°æ®ã€‚
- ç®€å•çš„æ¶æ„ï¼šæ¶æ„è¾ƒä¸ºç®€å•ï¼Œé€‚ç”¨äºè¾ƒå°çš„æ•°æ®é›†å’Œä»»åŠ¡ã€‚



### 2. é¸¢å°¾èŠ± MLP

1. å†³ç­–è¾¹ç•Œ

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240627-153841.png" alt="Image Description" width="600">
</p>


2. æºä»£ç 

```py
# å¯¼å…¥å¿…è¦çš„åº“
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.decomposition import PCA

# åŠ è½½æ•°æ®é›†
iris = load_iris()
X = iris.data
y = iris.target

# æ•°æ®æ ‡å‡†åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ä½¿ç”¨PCAé™ç»´åˆ°2ç»´
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# å°†æ•°æ®é›†æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)

# æ„å»ºMLPåˆ†ç±»å™¨
mlp = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42)
mlp.fit(X_train, y_train)

# å†³ç­–è¾¹ç•Œçš„å¯è§†åŒ–
x_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1
y_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),
                     np.arange(y_min, y_max, 0.02))

# ä½¿ç”¨åˆ†ç±»å™¨å¯¹ç½‘æ ¼ç‚¹è¿›è¡Œé¢„æµ‹
Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# ç»˜åˆ¶å†³ç­–è¾¹ç•Œ
plt.figure(figsize=(10, 5))
plt.contourf(xx, yy, Z, alpha=0.8)
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, edgecolor='k', s=20)
plt.title('Decision Boundary after PCA')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()
```

ğŸ“Œ ä»£ç è§£é‡Š

- æ•°æ®æ ‡å‡†åŒ–ï¼šæˆ‘ä»¬ä½¿ç”¨StandardScalerå¯¹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ã€‚
- PCAé™ç»´ï¼šä½¿ç”¨PCAå°†æ•°æ®ä»4ç»´é™åˆ°2ç»´ã€‚
- æ•°æ®é›†æ‹†åˆ†ï¼šå°†é™ç»´åçš„æ•°æ®é›†æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚
- è®­ç»ƒMLPåˆ†ç±»å™¨ï¼šæ„å»ºå¹¶è®­ç»ƒä¸€ä¸ªå…·æœ‰`ä¸¤ä¸ªéšè—å±‚`çš„MLPåˆ†ç±»å™¨ã€‚
- ç”Ÿæˆç½‘æ ¼å¹¶é¢„æµ‹ç±»åˆ«ï¼šåœ¨äºŒç»´ç‰¹å¾ç©ºé—´ä¸­ç”Ÿæˆä¸€ä¸ªç½‘æ ¼ç‚¹é›†åˆï¼Œå¹¶ä½¿ç”¨è®­ç»ƒå¥½çš„åˆ†ç±»å™¨å¯¹è¿™äº›ç½‘æ ¼ç‚¹è¿›è¡Œé¢„æµ‹ã€‚
- ç»˜åˆ¶å†³ç­–è¾¹ç•Œï¼šä½¿ç”¨contourfå‡½æ•°ç»˜åˆ¶å†³ç­–è¾¹ç•Œï¼Œå¹¶ä½¿ç”¨scatterå‡½æ•°ç»˜åˆ¶å®é™…æ•°æ®ç‚¹ã€‚



# 5. å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰

###  1. å·ç§¯æ ¸æå–ç‰¹å¾

- æ»¤æ³¢å™¨å’Œç‰¹å¾å›¾

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240827-164042.png" alt="Image Description" width="700">
</p>

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240701-161554.png" alt="Image Description" width="700">
</p>



### 2. å·ç§¯å±‚å’Œæ± åŒ–å±‚

- å·ç§¯å±‚å’Œæ± åŒ–å±‚

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240827-163143.png" alt="Image Description" width="700">
</p>


<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240701-162208.png" alt="Image Description" width="700">
</p>

ğŸ’ **å·ç§¯å±‚çš„åŸºæœ¬æ„æˆ**

1. å·ç§¯æ“ä½œï¼š

   - å·ç§¯å±‚é€šè¿‡æ‰§è¡Œå·ç§¯æ“ä½œæ¥å¤„ç†è¾“å…¥æ•°æ®ï¼ˆé€šå¸¸æ˜¯å›¾åƒï¼‰ã€‚è¿™ç§æ“ä½œåŒ…æ‹¬å°†ä¸€ç»„å°å‹çš„ã€å¯å­¦ä¹ çš„æ»¤æ³¢å™¨ï¼ˆæˆ–ç§°ä¸ºå·ç§¯æ ¸ï¼‰åº”ç”¨äºè¾“å…¥æ•°æ®ã€‚
   - æ¯ä¸ªæ»¤æ³¢å™¨éƒ½åœ¨è¾“å…¥å›¾åƒçš„å…¨å±€æˆ–éƒ¨åˆ†åŒºåŸŸä¸Šæ»‘åŠ¨ï¼Œå¯¹åº”çš„åŒºåŸŸè¿›è¡Œå…ƒç´ ä¹˜ç§¯åæ±‚å’Œï¼Œç”Ÿæˆç‰¹å¾å›¾çš„ä¸€ä¸ªåƒç´ ç‚¹ã€‚è¿™ä¸ªè¿‡ç¨‹åœ¨æ•´ä¸ªè¾“å…¥å›¾åƒä¸Šé‡å¤è¿›è¡Œï¼Œä»¥å½¢æˆå®Œæ•´çš„ç‰¹å¾å›¾ã€‚

2. æ»¤æ³¢å™¨å’Œç‰¹å¾å›¾ï¼š

   - æ»¤æ³¢å™¨è´Ÿè´£ä»è¾“å…¥å›¾åƒä¸­æå–ç‰¹å®šç±»å‹çš„ç‰¹å¾ï¼Œå¦‚è¾¹ç¼˜ã€è§’ç‚¹ã€çº¹ç†ç­‰ã€‚æ¯ä¸ªæ»¤æ³¢å™¨éƒ½å¯¹åº”äºè¾“å‡ºçš„ä¸€ä¸ªç‰¹å¾å›¾ï¼Œæ˜¾ç¤ºäº†è¾“å…¥å›¾åƒåœ¨è¯¥æ»¤æ³¢å™¨è¡¨ç¤ºçš„ç‰¹å¾ä¸Šçš„å“åº”å¼ºåº¦å’Œä½ç½®ã€‚
   - åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå·ç§¯å±‚å¯ä»¥åŒ…å«å¤šä¸ªæ»¤æ³¢å™¨ï¼Œæ¯ä¸ªæ»¤æ³¢å™¨äº§ç”Ÿä¸€ä¸ªç‹¬ç«‹çš„ç‰¹å¾å›¾ï¼Œè¿™äº›ç‰¹å¾å›¾å †å åœ¨ä¸€èµ·å½¢æˆè¾“å‡ºæ•°æ®ã€‚

ğŸ’ **å·ç§¯å±‚çš„å…³é”®å‚æ•°**

3. æ­¥é•¿ï¼ˆStrideï¼‰ï¼š

   - æ­¥é•¿å®šä¹‰äº†æ»¤æ³¢å™¨åœ¨è¾“å…¥å›¾åƒä¸Šæ»‘åŠ¨æ—¶æ¯æ¬¡ç§»åŠ¨çš„åƒç´ æ•°ã€‚è¾ƒå¤§çš„æ­¥é•¿ä¼šå‡å°è¾“å‡ºç‰¹å¾å›¾çš„å°ºå¯¸ï¼Œè€Œè¾ƒå°çš„æ­¥é•¿èƒ½ç”Ÿæˆæ›´è¯¦ç»†çš„ç‰¹å¾å›¾ã€‚

4. å¡«å……ï¼ˆPaddingï¼‰ï¼š

   - å¡«å……æ˜¯æŒ‡åœ¨è¾“å…¥å›¾åƒçš„è¾¹ç•Œå‘¨å›´å¡«å……ä¸€å®šæ•°é‡çš„åƒç´ ï¼ˆé€šå¸¸æ˜¯0ï¼‰ï¼Œä»¥å…è®¸æ»¤æ³¢å™¨è¦†ç›–åˆ°å›¾åƒçš„è¾¹ç¼˜éƒ¨åˆ†ã€‚è¿™æœ‰åŠ©äºæ§åˆ¶è¾“å‡ºç‰¹å¾å›¾çš„ç©ºé—´å°ºå¯¸ï¼Œå¹¶ä¿æŒè¾“å…¥å’Œè¾“å‡ºå°ºå¯¸çš„ä¸€è‡´æ€§ã€‚
     
ğŸ’ **å·ç§¯å±‚çš„ä¼˜ç‚¹å’ŒåŠŸèƒ½**

5. å‚æ•°å…±äº«ï¼š

   - åœ¨å·ç§¯å±‚ä¸­ï¼Œæ¯ä¸ªæ»¤æ³¢å™¨çš„å‚æ•°ï¼ˆå³å·ç§¯æ ¸çš„æƒé‡ï¼‰åœ¨æ•´ä¸ªè¾“å…¥å›¾åƒä¸Šæ˜¯å…±äº«çš„ã€‚è¿™ç§å‚æ•°å…±äº«æ˜¾è‘—å‡å°‘äº†æ¨¡å‹çš„å‚æ•°æ•°é‡ï¼Œé™ä½äº†è¿‡æ‹Ÿåˆçš„é£é™©ï¼Œå¹¶æé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

6. å±€éƒ¨è¿æ¥ï¼š

   - å·ç§¯å±‚é‡‡ç”¨å±€éƒ¨è¿æ¥çš„ç­–ç•¥ï¼Œå³æ¯ä¸ªç¥ç»å…ƒä»…ä¸è¾“å…¥æ•°æ®çš„ä¸€ä¸ªå±€éƒ¨åŒºåŸŸç›¸è¿æ¥ã€‚è¿™åˆ©ç”¨äº†å›¾åƒæ•°æ®çš„å±€éƒ¨ç©ºé—´å…³è”æ€§ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ•æ‰åˆ°å±€éƒ¨ç‰¹å¾ä¿¡æ¯ï¼Œå¹¶å‡å°‘äº†è®¡ç®—å¤æ‚åº¦ã€‚




### 3. æ± åŒ–å±‚


### 4. LeNet

### 5. AlexNet



# 6. å·ç§¯ç¥ç»ç½‘ç»œåˆ†ç±»MNISTæ‰‹å†™æ•°å­—

### 1. ä»£ç 


ğŸ“Œ **è¯´æ˜**

ä¸‹é¢ä»£ç å®ç°äº†ä¸€ä¸ªç®€å•çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æ¥è¯†åˆ«MNISTæ‰‹å†™æ•°å­—æ•°æ®é›†ã€‚å…·ä½“æ­¥éª¤åŒ…æ‹¬ï¼š

1. åŠ è½½å¹¶é¢„å¤„ç†MNISTæ•°æ®é›†ï¼Œå°†å›¾åƒæ•°æ®è°ƒæ•´ä¸ºé€‚åˆæ¨¡å‹è¾“å…¥çš„å½¢çŠ¶å¹¶å½’ä¸€åŒ–ã€‚
2. æ„å»ºä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ŒåŒ…æ‹¬å·ç§¯å±‚ã€æ± åŒ–å±‚ã€å…¨è¿æ¥å±‚ï¼Œä»¥åŠæœ€ç»ˆçš„åˆ†ç±»å±‚ã€‚
3. ç¼–è¯‘æ¨¡å‹ï¼Œä½¿ç”¨Adamä¼˜åŒ–å™¨å’Œäº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œå¹¶å®šä¹‰å‡†ç¡®ç‡ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ã€‚
4. è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨è®­ç»ƒé›†å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡ŒéªŒè¯ã€‚
5. è¯„ä¼°æ¨¡å‹ï¼Œä½¿ç”¨æµ‹è¯•é›†è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶æ‰“å°æµ‹è¯•å‡†ç¡®ç‡ã€‚
6. ç”Ÿæˆé¢„æµ‹ç»“æœï¼Œå¹¶å¯è§†åŒ–å‰10å¼ æµ‹è¯•å›¾åƒçš„é¢„æµ‹ç»“æœï¼Œé€šè¿‡é¢œè‰²åŒºåˆ†é¢„æµ‹æ˜¯å¦æ­£ç¡®ã€‚

```py
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np

# åŠ è½½MNISTæ•°æ®é›†
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()

# æ•°æ®é¢„å¤„ç†ï¼šè°ƒæ•´å½¢çŠ¶å¹¶å½’ä¸€åŒ–åˆ°0-1ä¹‹é—´
train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255

# æ„å»ºå·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# æ˜¾ç¤ºæ¨¡å‹ç»“æ„
model.summary()

# ç¼–è¯‘æ¨¡å‹
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# è®­ç»ƒæ¨¡å‹
model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.1)

# è¯„ä¼°æ¨¡å‹
test_loss, test_acc = model.evaluate(test_images, test_labels)
print(f"Test accuracy: {test_acc}")

# ç”Ÿæˆé¢„æµ‹
predictions = model.predict(test_images)

# å¯è§†åŒ–é¢„æµ‹ç»“æœ
def plot_image(i, predictions_array, true_label, img):
    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])

    plt.imshow(img.reshape(28, 28), cmap=plt.cm.binary)

    predicted_label = np.argmax(predictions_array)
    if predicted_label == true_label:
        color = 'blue'
    else:
        color = 'red'

    plt.xlabel(f"{predicted_label} ({true_label})", color=color)

for i in range(10):
    plt.figure(figsize=(6,3))
    plt.subplot(1,2,1)
    plot_image(i, predictions, test_labels, test_images)
    plt.show()
```


### 2. ä»£ç æ³¨é‡Š

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240827-152256.png" alt="Image Description" width="700">
</p>





# 7. è‡ªç¼–ç å™¨



# å‚è€ƒæ–‡çŒ®

1. "The Hundred-Page Machine Learning Book" by Andriy Burkov
2. "Deep Learning" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville


