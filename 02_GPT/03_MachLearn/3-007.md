# 图神经网络

# 1. 图的表示和特性

## 1. 概述

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240927-142954.png" alt="Image Description" width="700">
</p>

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240920-142703.png" alt="Image Description" width="700">
</p>

## 2. 图信号处理

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240920-143947.png" alt="Image Description" width="700">
</p>


### 1. 图的拉普拉斯矩阵

- 邻接矩阵

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240927-102556.png" alt="Image Description" width="700">
</p>

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240920-145057.png" alt="Image Description" width="700">
</p>


### 2. 图傅里叶变换

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240920-145948.png" alt="Image Description" width="700">
</p>


## 3. 复杂图

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240920-153210.png" alt="Image Description" width="700">
</p>


## 4. 特征学习和图嵌入

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240920-155750.png" alt="Image Description" width="700">
</p>


## 5. 表示学习

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240925-170214.png" alt="Image Description" width="700">
</p>


## 6. GAT图注意力网络

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240928-172521.png" alt="Image Description" width="700">
</p>


# 2. 节点嵌入及邻域重建

## 1. 概述与关键术语

### 1. 图嵌入简介

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240923-145606.png" alt="Image Description" width="700">
</p>


### 2. 节点共现

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240923-151435.png" alt="Image Description" width="700">
</p>


### 3. 映射函数与嵌入矩阵

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240923-152628.png" alt="Image Description" width="700">
</p>


### 4. one-hot编码与嵌入向量

- one-hot编码

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240927-102422.png" alt="Image Description" width="700">
</p>

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240923-153859.png" alt="Image Description" width="700">
</p>


### 5. 中心节点与上下文节点嵌入向量

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240923-164741.png" alt="Image Description" width="700">
</p>



## 2. 简单图的嵌入算法

### 1. 概述

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240923-150408.png" alt="Image Description" width="700">
</p>


### 2. 节点共现

#### 1. 保持节点共现

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240923-155914.png" alt="Image Description" width="700">
</p>

#### 2. 重构器和目标函数

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240923-163220.png" alt="Image Description" width="700">
</p>


#### 3. 层次化 Softmax

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240926-141456.png" alt="Image Description" width="700">
</p>

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240926-142105.png" alt="Image Description" width="700">
</p>

#### 4. 负采样

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240926-144949.png" alt="Image Description" width="700">
</p>

#### 5. node2vec算法

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240926-144317.png" alt="Image Description" width="700">
</p>

#### 6. LINE算法


### 3. 保留结构角色

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240926-143827.png" alt="Image Description" width="700">
</p>

### 4. 保留节点状态

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240926-145801.png" alt="Image Description" width="700">
</p>

### 5. 保留社区结构

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240926-150815.png" alt="Image Description" width="700">
</p>




## 3. 复杂图的嵌入方法

### 1. 异构图嵌入

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240926-152033.png" alt="Image Description" width="700">
</p>

### 2. 二分图嵌入

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240926-153248.png" alt="Image Description" width="700">
</p>

### 3. 多维图嵌入

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240926-170027.png" alt="Image Description" width="700">
</p>

### 4. 带符号图嵌入

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240926-170807.png" alt="Image Description" width="700">
</p>


### 5. 超图嵌入

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240926-173420.png" alt="Image Description" width="700">
</p>




# 3. 图神经网络

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240927-142915.png" alt="Image Description" width="700">
</p>

## 1. 图神经网络分类

### 1. 


### 2. 四种不同类型的GNN架构

- 结构示意图

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240930-102141.png" alt="Image Description" width="700">
</p>

- 架构说明

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240930-102527.png" alt="Image Description" width="700">
</p>




## 2. 一般的图神经网络框架

### 1. 面向节点的任务的一般框架



### 2. 面向图的任务的一般框架




## 3. 图滤波器

### 1. 基于谱的图滤波器




### 2. 基于空间的图滤波器


## 4. 图池化

### 1. 扁平的图池化



### 2. 分层的图池化





## 5. 图神经网络的参数学习

### 1. 面向节点分类的参数学习

### 2. 面向图分类的参数学习




# 4. Cora 引文网络数据集

- Cora 引文网络数据集是一个常用于机器学习和图神经网络研究的基准数据集，主要用于分类和聚类任务。
- 该数据集包含 2708 篇机器学习领域的学术论文，这些论文分为 7 个类别。每篇论文由一个 1433 维的词袋特征向量表示，用于描述论文的内容。论文之间的引用关系构成了一个无向图，边表示引用关系，节点代表论文。Cora 数据集的目标通常是通过图结构和节点特征进行节点分类。
- 该数据集广泛应用于半监督学习和图卷积网络（GCN）的研究。


- 数据集下载和查看参考：https://github.com/Yiwei666/01_python_script/blob/main/02_GPT/03_MachLearn/3-002.md

### 1. 实例化图卷积网络模型

1. 代码

```py
import torch
from torch_geometric.datasets import Planetoid
from torch_geometric.transforms import NormalizeFeatures
from torch_geometric.nn import GCNConv
import torch.nn.functional as F

# 加载 Cora 数据集
dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())

class GCN(torch.nn.Module):
    def __init__(self, hidden_channels):
        super().__init__()
        torch.manual_seed(1234567)
        self.conv1 = GCNConv(dataset.num_features, hidden_channels)  # 使用 dataset.num_features
        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)   # 使用 dataset.num_classes

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv2(x, edge_index)
        return x

# 实例化模型
model = GCN(hidden_channels=16)
print(model)
```

2. 代码解释

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240928-171044.png" alt="Image Description" width="700">
</p>

3. 边（引用关系）在图卷积中的使用

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240928-192536.png" alt="Image Description" width="700">
</p>

4. 图卷积过程中的特征、边和节点数量变化

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240928-192924.png" alt="Image Description" width="700">
</p>



### 2. 未训练的 GCN 模型节点嵌入可视化

- 可视化

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240927-162408.png" alt="Image Description" width="500">
</p>

- 代码

```py
import torch
from torch_geometric.datasets import Planetoid
from torch_geometric.transforms import NormalizeFeatures
from torch_geometric.nn import GCNConv
import torch.nn.functional as F
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

# 加载 Cora 数据集
dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())
data = dataset[0]

# 定义 GCN 模型
class GCN(torch.nn.Module):
    def __init__(self, hidden_channels):
        super().__init__()
        torch.manual_seed(1234567)
        self.conv1 = GCNConv(dataset.num_features, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv2(x, edge_index)
        return x

# 可视化函数
def visualize(h, color):
    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())
    plt.figure(figsize=(10,10))
    plt.xticks([])
    plt.yticks([])
    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap="Set2")
    plt.show()

# 实例化模型并进入评估模式
model = GCN(hidden_channels=16)
model.eval()

# 获取模型输出（节点嵌入）
out = model(data.x, data.edge_index)

# 调用可视化函数，可视化未训练的节点嵌入
visualize(out, color=data.y)
```

- 代码解释

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240927-162806.png" alt="Image Description" width="700">
</p>


### 3. GCN 模型训练、评估及可视化

1. 可视化

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240927-170717.png" alt="Image Description" width="500">
</p>


2. 代码

```py
import torch
from torch_geometric.datasets import Planetoid
from torch_geometric.transforms import NormalizeFeatures
from torch_geometric.nn import GCNConv
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

# 加载 Cora 数据集
dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())
data = dataset[0]

# 定义 GCN 模型
class GCN(torch.nn.Module):
    def __init__(self, hidden_channels):
        super().__init__()
        torch.manual_seed(1234567)
        self.conv1 = GCNConv(dataset.num_features, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv2(x, edge_index)
        return x

# 可视化函数
def visualize(h, color):
    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())
    plt.figure(figsize=(10, 10))
    plt.xticks([])
    plt.yticks([])
    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap="Set2")
    plt.show()

# 训练函数
def train():
    model.train()
    optimizer.zero_grad()  # 清除上一次的梯度
    out = model(data.x, data.edge_index)  # 前向传播
    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # 计算损失
    loss.backward()  # 反向传播
    optimizer.step()  # 更新模型参数
    return loss

# 测试函数
def test():
    model.eval()
    out = model(data.x, data.edge_index)
    pred = out.argmax(dim=1)  # 预测类别
    test_correct = pred[data.test_mask] == data.y[data.test_mask]  # 比较预测值和真实值
    test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # 计算准确率
    return test_acc

# 实例化模型，定义优化器和损失函数
model = GCN(hidden_channels=16)
optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)
criterion = torch.nn.CrossEntropyLoss()

# 训练模型
for epoch in range(1, 101):  # 训练 100 个 epoch
    loss = train()
    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')

# 测试模型
test_acc = test()
print(f'Test Accuracy: {test_acc:.4f}')

# 可视化训练后的节点嵌入
model.eval()  # 进入评估模式
out = model(data.x, data.edge_index)  # 获取模型输出
visualize(out, color=data.y)  # 调用可视化函数
```

3. 解释

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240927-171253.png" alt="Image Description" width="700">
</p>


### 4.  GATConv 模型的定义、训练、测试、可视化

1. 可视化

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240928-171411.png" alt="Image Description" width="500">
</p>

2. 代码

```py
import torch
from torch_geometric.datasets import Planetoid
from torch_geometric.transforms import NormalizeFeatures
from torch_geometric.nn import GATConv
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
import numpy as np

# 加载 Cora 数据集
dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())
data = dataset[0]

# 定义 GAT 模型
class GAT(torch.nn.Module):
    def __init__(self, hidden_channels, heads):
        super().__init__()
        torch.manual_seed(1234567)
        self.conv1 = GATConv(dataset.num_features, hidden_channels, heads=heads)
        self.conv2 = GATConv(hidden_channels * heads, dataset.num_classes, heads=1)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.dropout(x, p=0.6, training=self.training)
        x = F.elu(x)  # 使用 F.elu(x)
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.conv2(x, edge_index)
        return x

# 可视化函数
def visualize(h, color):
    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())
    plt.figure(figsize=(10, 10))
    plt.xticks([])
    plt.yticks([])
    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap="Set2")
    plt.show()

# 训练函数
def train():
    model.train()
    optimizer.zero_grad()
    out = model(data.x, data.edge_index)
    loss = criterion(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()
    return loss

# 测试函数
def test(mask):
    model.eval()
    out = model(data.x, data.edge_index)
    pred = out.argmax(dim=1)
    correct = pred[mask] == data.y[mask]
    return int(correct.sum()) / int(mask.sum())

# 实例化模型，定义优化器和损失函数
model = GAT(hidden_channels=8, heads=8)
optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)
criterion = torch.nn.CrossEntropyLoss()

# 记录验证集和测试集的准确率
val_acc_all = []
test_acc_all = []

# 训练模型
for epoch in range(1, 101):  # 训练 100 个 epoch
    loss = train()
    val_acc = test(data.val_mask)
    test_acc = test(data.test_mask)
    val_acc_all.append(val_acc)
    test_acc_all.append(test_acc)
    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')

# 绘制验证集和测试集的准确率
plt.figure(figsize=(12, 8))
plt.plot(np.arange(1, len(val_acc_all)+1), val_acc_all, label="Validation accuracy")
plt.plot(np.arange(1, len(test_acc_all)+1), test_acc_all, label="Test accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend(fontsize='x-large')
plt.savefig("gat_loss.png")
plt.show()

# 可视化训练后的节点嵌入
model.eval()
out = model(data.x, data.edge_index)
visualize(out, color=data.y)
```

3. 解释

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240928-172250.png" alt="Image Description" width="700">
</p>


# 5. CiteSeer 数据集

CiteSeer 数据集是一个学术文献引用网络数据集，包含 3327 篇论文（节点），它们通过 9104 条引用关系（边）相互连接。每篇论文的内容由 3703 维特征向量表示，并且每篇论文属于 6 个类别中的一个。该数据集广泛用于图神经网络的节点分类任务，旨在通过节点的特征和引用关系预测每篇论文的学术类别。

### 1. 图卷积神经网络预测

1. 代码

```py
import torch
from torch_geometric.datasets import Planetoid
from torch_geometric.transforms import NormalizeFeatures
from torch_geometric.nn import GCNConv
import torch.nn.functional as F
import matplotlib.pyplot as plt

# 加载 CiteSeer 数据集
dataset = Planetoid(root='data/Planetoid', name='CiteSeer', transform=NormalizeFeatures())
data = dataset[0]  # CiteSeer 只有一个图，数据集中的第一个图

# 定义 GCN 模型
class GCN(torch.nn.Module):
    def __init__(self, hidden_channels):
        super().__init__()
        torch.manual_seed(1234567)
        self.conv1 = GCNConv(dataset.num_features, hidden_channels)  # 第一层卷积
        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)   # 第二层卷积

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)  # 第一层卷积操作
        x = x.relu()                   # 激活函数
        x = F.dropout(x, p=0.5, training=self.training)  # Dropout 防止过拟合
        x = self.conv2(x, edge_index)  # 第二层卷积操作
        return F.log_softmax(x, dim=1)  # 使用 log_softmax 计算分类分数

# 初始化模型
model = GCN(hidden_channels=16)
print(model)

# 定义优化器和损失函数
optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Adam 优化器
criterion = torch.nn.CrossEntropyLoss()  # 交叉熵损失函数

# 定义训练函数
def train():
    model.train()  # 将模型设置为训练模式
    optimizer.zero_grad()  # 梯度清零
    out = model(data.x, data.edge_index)  # 前向传播
    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # 计算损失（仅对训练集）
    loss.backward()  # 反向传播
    optimizer.step()  # 优化参数
    return loss.item()

# 定义测试函数
def test():
    model.eval()  # 设置模型为评估模式
    out = model(data.x, data.edge_index)  # 前向传播
    pred = out.argmax(dim=1)  # 预测类别
    accs = []  # 存储训练集、验证集和测试集的准确率
    for mask in [data.train_mask, data.val_mask, data.test_mask]:
        correct = pred[mask].eq(data.y[mask]).sum().item()  # 计算预测正确的数量
        acc = correct / mask.sum().item()  # 计算准确率
        accs.append(acc)
    return accs

# 记录损失和准确率
train_losses = []
train_accuracies = []
val_accuracies = []
test_accuracies = []

# 训练模型
epochs = 200
for epoch in range(epochs):
    loss = train()  # 训练模型
    train_acc, val_acc, test_acc = test()  # 测试模型在训练集、验证集和测试集上的准确率
    
    # 保存损失和准确率
    train_losses.append(loss)
    train_accuracies.append(train_acc)
    val_accuracies.append(val_acc)
    test_accuracies.append(test_acc)
    
    if epoch % 10 == 0:
        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, '
              f'Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')

# 输出最终测试集准确率
train_acc, val_acc, test_acc = test()
print(f'Final Test Accuracy: {test_acc:.4f}')

# 可视化损失和准确率变化
epochs_range = range(epochs)
plt.figure(figsize=(12, 6))

# 绘制训练损失
plt.subplot(1, 2, 1)
plt.plot(epochs_range, train_losses, label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training Loss over Epochs')
plt.legend()

# 绘制训练、验证和测试准确率
plt.subplot(1, 2, 2)
plt.plot(epochs_range, train_accuracies, label='Train Accuracy')
plt.plot(epochs_range, val_accuracies, label='Val Accuracy')
plt.plot(epochs_range, test_accuracies, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy over Epochs')
plt.legend()

plt.tight_layout()
plt.show()
```

2. 可视化

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240929-152502.png" alt="Image Description" width="700">
</p>


### 2. t-SNE降维可视化

1. 代码

```py
import torch
from torch_geometric.datasets import Planetoid
from torch_geometric.transforms import NormalizeFeatures
from torch_geometric.nn import GCNConv
import torch.nn.functional as F
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
import numpy as np

# 加载 CiteSeer 数据集
dataset = Planetoid(root='data/Planetoid', name='CiteSeer', transform=NormalizeFeatures())
data = dataset[0]  # CiteSeer 只有一个图，数据集中的第一个图

# 定义 GCN 模型
class GCN(torch.nn.Module):
    def __init__(self, hidden_channels):
        super().__init__()
        torch.manual_seed(1234567)
        self.conv1 = GCNConv(dataset.num_features, hidden_channels)  # 第一层卷积
        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)   # 第二层卷积

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)  # 第一层卷积操作
        x = x.relu()                   # 激活函数
        x = F.dropout(x, p=0.5, training=self.training)  # Dropout 防止过拟合
        x = self.conv2(x, edge_index)  # 第二层卷积操作
        return x  # 这里我们不使用 log_softmax，因为我们要提取最后一层的嵌入

# 初始化模型
model = GCN(hidden_channels=16)
print(model)

# 定义优化器和损失函数
optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Adam 优化器
criterion = torch.nn.CrossEntropyLoss()  # 交叉熵损失函数

# 定义训练函数
def train():
    model.train()  # 将模型设置为训练模式
    optimizer.zero_grad()  # 梯度清零
    out = model(data.x, data.edge_index)  # 前向传播
    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # 计算损失（仅对训练集）
    loss.backward()  # 反向传播
    optimizer.step()  # 优化参数
    return loss.item()

# 定义测试函数
def test():
    model.eval()  # 设置模型为评估模式
    out = model(data.x, data.edge_index)  # 前向传播
    pred = out.argmax(dim=1)  # 预测类别
    accs = []  # 存储训练集、验证集和测试集的准确率
    for mask in [data.train_mask, data.val_mask, data.test_mask]:
        correct = pred[mask].eq(data.y[mask]).sum().item()  # 计算预测正确的数量
        acc = correct / mask.sum().item()  # 计算准确率
        accs.append(acc)
    return accs

# 记录损失和准确率
train_losses = []
train_accuracies = []
val_accuracies = []
test_accuracies = []

# 训练模型
epochs = 200
for epoch in range(epochs):
    loss = train()  # 训练模型
    train_acc, val_acc, test_acc = test()  # 测试模型在训练集、验证集和测试集上的准确率
    
    # 保存损失和准确率
    train_losses.append(loss)
    train_accuracies.append(train_acc)
    val_accuracies.append(val_acc)
    test_accuracies.append(test_acc)
    
    if epoch % 10 == 0:
        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, '
              f'Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')

# 提取嵌入向量进行可视化
model.eval()
embeddings = model(data.x, data.edge_index).detach().numpy()  # 获取最后一层的嵌入

# 使用 t-SNE 进行降维
tsne = TSNE(n_components=2, random_state=42)
embeddings_2d = tsne.fit_transform(embeddings)

# 可视化 t-SNE 降维后的嵌入
plt.figure(figsize=(10, 8))

# 根据节点的真实类别进行颜色标记
colors = ['r', 'g', 'b', 'c', 'm', 'y']
for i in range(dataset.num_classes):
    idx = data.y == i
    plt.scatter(embeddings_2d[idx, 0], embeddings_2d[idx, 1], label=f'Class {i}', s=20, alpha=0.7, c=colors[i])

plt.legend()
plt.title("t-SNE Visualization of GCN Embeddings (CiteSeer)")
plt.show()
```

2. 可视化

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240929-153156.png" alt="Image Description" width="500">
</p>


### 3. 引入图注意力机制

- 代码

```py
import torch
from torch_geometric.datasets import Planetoid
from torch_geometric.transforms import NormalizeFeatures
from torch_geometric.nn import GATConv
import torch.nn.functional as F
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
import numpy as np

# 加载 CiteSeer 数据集
dataset = Planetoid(root='data/Planetoid', name='CiteSeer', transform=NormalizeFeatures())
data = dataset[0]  # CiteSeer 只有一个图，数据集中的第一个图

# 定义 GAT 模型
class GAT(torch.nn.Module):
    def __init__(self, hidden_channels, heads=8):
        super().__init__()
        torch.manual_seed(1234567)
        self.conv1 = GATConv(dataset.num_features, hidden_channels, heads=heads, concat=True)  # 多头注意力机制
        self.conv2 = GATConv(hidden_channels * heads, dataset.num_classes, heads=1, concat=False)  # 输出层不需要concat

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.elu(x)  # ELU 激活函数
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)  # 使用 log_softmax 计算分类分数

# 初始化模型
model = GAT(hidden_channels=8)  # 使用 8 维的隐藏层和 8 个注意力头
print(model)

# 定义优化器和损失函数
optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)  # Adam 优化器
criterion = torch.nn.CrossEntropyLoss()  # 交叉熵损失函数

# 定义训练函数
def train():
    model.train()  # 将模型设置为训练模式
    optimizer.zero_grad()  # 梯度清零
    out = model(data.x, data.edge_index)  # 前向传播
    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # 计算损失（仅对训练集）
    loss.backward()  # 反向传播
    optimizer.step()  # 优化参数
    return loss.item()

# 定义测试函数
def test():
    model.eval()  # 设置模型为评估模式
    out = model(data.x, data.edge_index)  # 前向传播
    pred = out.argmax(dim=1)  # 预测类别
    accs = []  # 存储训练集、验证集和测试集的准确率
    for mask in [data.train_mask, data.val_mask, data.test_mask]:
        correct = pred[mask].eq(data.y[mask]).sum().item()  # 计算预测正确的数量
        acc = correct / mask.sum().item()  # 计算准确率
        accs.append(acc)
    return accs

# 记录损失和准确率
train_losses = []
train_accuracies = []
val_accuracies = []
test_accuracies = []

# 训练模型
epochs = 200
for epoch in range(epochs):
    loss = train()  # 训练模型
    train_acc, val_acc, test_acc = test()  # 测试模型在训练集、验证集和测试集上的准确率
    
    # 保存损失和准确率
    train_losses.append(loss)
    train_accuracies.append(train_acc)
    val_accuracies.append(val_acc)
    test_accuracies.append(test_acc)
    
    if epoch % 10 == 0:
        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, '
              f'Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')

# 提取嵌入向量进行可视化
model.eval()
embeddings = model(data.x, data.edge_index).detach().numpy()  # 获取最后一层的嵌入

# 使用 t-SNE 进行降维
tsne = TSNE(n_components=2, random_state=42)
embeddings_2d = tsne.fit_transform(embeddings)

# 可视化 t-SNE 降维后的嵌入
plt.figure(figsize=(10, 8))

# 根据节点的真实类别进行颜色标记
colors = ['r', 'g', 'b', 'c', 'm', 'y']
for i in range(dataset.num_classes):
    idx = data.y == i
    plt.scatter(embeddings_2d[idx, 0], embeddings_2d[idx, 1], label=f'Class {i}', s=20, alpha=0.7, c=colors[i])

plt.legend()
plt.title("t-SNE Visualization of GAT Embeddings (CiteSeer)")
plt.show()

# 可视化损失和准确率变化
epochs_range = range(epochs)
plt.figure(figsize=(12, 6))

# 绘制训练损失
plt.subplot(1, 2, 1)
plt.plot(epochs_range, train_losses, label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training Loss over Epochs')
plt.legend()

# 绘制训练、验证和测试准确率
plt.subplot(1, 2, 2)
plt.plot(epochs_range, train_accuracies, label='Train Accuracy')
plt.plot(epochs_range, val_accuracies, label='Val Accuracy')
plt.plot(epochs_range, test_accuracies, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

# 输出最终测试集准确率
train_acc, val_acc, test_acc = test()
print(f'Final Test Accuracy: {test_acc:.4f}')
```



# 参考资料

1. Ma Y, Tang J. Deep learning on graphs[M]. Cambridge University Press, 2021.
2. Hamilton W L. Graph representation learning[M]. Morgan & Claypool Publishers, 2020.
3. [A Comprehensive Introduction to Graph Neural Networks (GNNs)](https://www.datacamp.com/tutorial/comprehensive-introduction-graph-neural-networks-gnns-tutorial)
4. Wu Z, Pan S, Chen F, et al. A comprehensive survey on graph neural networks[J]. IEEE transactions on neural networks and learning systems, 2020, 32(1): 4-24.
5. Scarselli F, Gori M, Tsoi A C, et al. The graph neural network model[J]. IEEE transactions on neural networks, 2008, 20(1): 61-80.
6. Liu Z, Zhou J. Introduction to graph neural networks[M]. Springer Nature, 2022.






